# file: C:\Users\kriti\AppData\Roaming\Python\Python313\site-packages\torch\cuda\memory.py
# hypothesis_version: 6.148.8

[750, 768, 1000, 1024, '-', '.', '=', 'Active allocs', 'Active memory', 'Allocated memory', 'Allocations', 'B  ', 'GPU reserved memory', 'GiB', 'K', 'KiB', 'M', 'MemPool', 'MemPoolContext', 'MiB', 'Oversize allocations', 'PiB', 'Requested memory', 'TiB', '_', '_MemPool', '_MemPoolContext', '_cuda_CUDAAllocator', '_cuda_releasePool', 'active', 'active_bytes', 'all', 'allocated', 'allocated_bytes', 'allocation', 'current', 'device', 'dump_snapshot.pickle', 'empty_cache', 'freed', 'host_memory_stats', 'inactive_split', 'inactive_split_bytes', 'large_pool', 'list_gpu_processes', 'max_memory_allocated', 'max_memory_cached', 'max_memory_reserved', 'mem_get_info', 'memory_allocated', 'memory_cached', 'memory_reserved', 'memory_snapshot', 'memory_stats', 'memory_summary', 'memory_usage', 'output.svg', 'oversize_allocations', 'oversize_segments', 'peak', 'pid', 'requested_bytes', 'reserved_bytes', 'segment', 'segments', 'small_pool', 'state', 'use_mem_pool', 'vram_mem', 'w', 'wb', '|', '|\n', '|\n|']