# file: C:\Users\kriti\AppData\Roaming\Python\Python313\site-packages\torch\_higher_order_ops\flex_attention.py
# hypothesis_version: 6.148.8

['call_function', 'flex_attention', 'fw_graph', 'inf', 'joint_graph', 'mask_graph', 'mode', 'sdpa_mask', 'sdpa_score']